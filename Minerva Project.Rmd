---
title: "Minerva Project"
author: "Andrew Borozan"
date: "`r Sys.Date()`"
output: html_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  out.width = "100%",
  message=FALSE,
  warning=FALSE
)

```

# Minerva Project Data Exploration

In this project we will be examining survey data from students along with assessment data on students. We will develop insights and offer exploration for further study.

First, we load in packages that may help us in our exploration of the data. Then, we will read in the data provided by Minerva.

```{r Setting up the Environment, message=FALSE, warning=FALSE}
library(pacman)
p_load(tidyverse, skimr, scales, rmarkdown, magrittr, lubridate, janitor, htmltab, ggrepel, viridis, ggthemes, knitr, reactable, stringr.plus, ggridges, readxl, reactablefmtr, showtext, ggpubr, sentimentr, tm, plotly, tinytex)
options(scipen=999)
theme_set(theme_light())
```

```{r Loading in Data, message=FALSE, warning=FALSE}
survey <- read_excel(path = "C:\\Users\\andre\\Downloads\\ERA Performance Assignment Data.xlsx", sheet = "Student Course Survey", trim_ws = TRUE)
outcomes <- read_excel(path = "C:\\Users\\andre\\Downloads\\ERA Performance Assignment Data.xlsx", sheet = "Course Learning Outcomes", trim_ws = TRUE)
```

# Student Course Survey

Let's look at the survey data first.

```{r Cleaning and Skimming, message=FALSE, warning=FALSE}
#First, let's clean the variable names.   
survey <- survey %>% clean_names()

#Let's remove the first row, which contains each question. We will add the questions in manually in tables and charts below. 
survey_clean <- survey %>% slice(-1)

#Let's get a look at the overall structure of the data
skim(survey_clean)
  
```

The survey data includes a response to questions on a Likert scale and two free response questions (which typically had lower response rates - 44% and 55%). The questions are grouped by type:

-   Time spent per week

-   Agreeableness towards statements about the course

-   Effectiveness of different elements of the course

-   Effectiveness of processes within the course

Free response questions addressed areas of improvement and overall effectiveness.

The first question addresses the amount of time spent engaged with course material per week by the student.

```{r Time spent per week}

font_add_google("Exo", "exo")

showtext_auto()

#We can take a look in tabular format the time spent preparing each week 
survey_clean %>% mutate(q1 = factor(x = q1, levels = c("30 minutes or less", "1-2 hours", "2-3 hours", "3-4 hours", "5 hours or more"))) %>% count(q1) %>% 
  mutate(percent_respondents = percent(round(n/sum(n), digits = 4))) %>% 
  rename("How much time per week have you typically spent throughout the semester preparing for this class?" = "q1", 
         "Number of Responses" = n,
         "Percent of Responses" = percent_respondents)  %>% 
  reactable(theme = fivethirtyeight(), striped = TRUE)

#And as a histogram
survey_clean %>% mutate(q1 = factor(x = q1, levels = c("30 minutes or less", "1-2 hours", "2-3 hours", "3-4 hours", "5 hours or more"))) %>% count(q1, sort = TRUE) %>% 
  ggplot(aes(q1, n, fill = q1)) +
  geom_histogram(stat = "identity", show.legend = FALSE)+
  scale_fill_viridis(discrete = TRUE, option = "magma", begin = .95, end = .5)+
  scale_y_continuous(expand = c(0,0), limits = c(0, 40))+
  labs(x = "Number of hours per week", y = "Number of responses", title = "How much time per week have you typically spent throughout the semester preparing for this class?")+
  theme(text = element_text(family = "exo"))

```

A cursory glance suggests a roughly normal distribution. Many of the responses gravitated towards the 2-3 hour range. 83% of respondents said they spend between 1 and 4 hours a week.

Next, to the first grouping of questions. The first set of questions used a 4 point Likert scale of agreeableness to a statement. We will look at each question and the number of responses for each point on the Likert scale.

```{r  Agreeableness towards statements about the course, out.width= "100%"}
# Question 2.1 in tabular format
q2.1_tab <- survey_clean %>% select(starts_with("q2")) %>% 
  mutate(q2_1 = factor(q2_1, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  count(q2_1) %>% mutate(Number_of_Responses = n, percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
  rename("For this course, rate your level of agreement with the following statements: - I expect to be able to use what I have learned in this course in the future." = "q2_1", 
         "Number of Responses" = "Number_of_Responses", 
         "Percent of Responses" = "percent_respondents") %>% 
  select(-n) %>% reactable(wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE)


#Question 2.1 in a histogram
q2.1_hist <- survey_clean %>% select(starts_with("q2")) %>% count(q2_1, sort = TRUE) %>% mutate(percent_respondents = percent(n/sum(n), accuracy = .1),
q2_1 = factor(q2_1, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  ggplot(aes(q2_1, n, fill = q2_1)) +
  geom_histogram(stat = "identity", show.legend = FALSE)+
  scale_fill_viridis(discrete = TRUE, option = "magma", begin = .95, end = .5)+
  labs(x = "", y = "Number of responses", title = "I expect to be able to use what I have learned in this course in the future.")+
  geom_text(aes(label = percent_respondents), color = "black", size = 6,
            vjust = -.1,
            family = "exo")+
  scale_y_continuous(breaks = c(10, 20, 30, 40, 50, 60, 70), limits = c(0, 60), expand = c(0, 0))+
  theme(text = element_text(family = "exo", size = 20))

# Question 2.2 in tabular format
q2.2_tab <- survey_clean %>% select(starts_with("q2")) %>% 
  mutate(q2_2 = factor(q2_2, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  count(q2_2) %>% mutate(Number_of_Responses = n, 
                                                                        percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
  rename("For this course, rate your level of agreement with the following statements: - Course content was relevant to the topic and learning outcomes in this course." = "q2_2", 
         "Number of Responses" = "Number_of_Responses", 
         "Percent of Responses" = "percent_respondents") %>% 
  select(-n) %>% reactable(wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE)

# Question 2.2 in histogram
q2.2_hist <- survey_clean %>% select(starts_with("q2")) %>% count(q2_2, sort = TRUE) %>% mutate(percent_respondents = percent(n/sum(n), accuracy = .1),
q2_2 = factor(q2_2, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  ggplot(aes(q2_2, n, fill = q2_2)) +
  geom_histogram(stat = "identity", show.legend = FALSE)+
  scale_fill_viridis(discrete = TRUE, option = "magma", begin = .95, end = .5)+
  labs(x = "", y = "Number of responses", title = "Course content was relevant to the topic and learning outcomes in this course.")+
  geom_text(aes(label = percent_respondents), color = "black", size = 6,
            vjust = -.1,
            family = "exo")+
  scale_y_continuous(breaks = c(10, 20, 30, 40, 50, 60, 70), limits = c(0,70), expand = c(0, 0))+
  theme(text = element_text(family = "exo", size = 20))

# Question 2.3 in tabular format
q2.3_tab <- survey_clean %>% select(starts_with("q2")) %>% 
  mutate(q2_3 = factor(q2_3, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  count(q2_3) %>% mutate(Number_of_Responses = n, 
                                                                                   percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
  rename("For this course, rate your level of agreement with the following statements: - Course assignments allowed me to demonstrate my understanding of what I have learned in the course." = "q2_3", 
         "Number of Responses" = "Number_of_Responses", 
         "Percent of Responses" = "percent_respondents") %>% 
  select(-n) %>% reactable(wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE)

# Question 2.3 in histogram
q2.3_hist <- survey_clean %>% select(starts_with("q2")) %>% count(q2_3, sort = TRUE) %>% mutate(percent_respondents = percent(n/sum(n), accuracy = .1),
q2_3 = factor(q2_3, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  ggplot(aes(q2_3, n, fill = q2_3)) +
  geom_histogram(stat = "identity", show.legend = FALSE)+
  scale_fill_viridis(discrete = TRUE, option = "magma", begin = .95, end = .5)+
  labs(x = "", y = "Number of responses", title = "Course assignments allowed me to demonstrate my understanding of what I have learned in the course.")+
  geom_text(aes(label = percent_respondents), color = "black", size = 6,
            vjust = -.1,
            family = "exo")+
  scale_y_continuous(breaks = c(10, 20, 30, 40, 50, 60), limits = c(0, 60), expand = c(0, 0))+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 17))


# Question 2.4 in tabular format
q2.4_tab <- survey_clean %>% select(starts_with("q2")) %>% 
  mutate(q2_4 = factor(q2_4, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  count(q2_4) %>% mutate(Number_of_Responses = n, 
                                                                                   percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
  rename("For this course, rate your level of agreement with the following statements: - The course stimulated new ways of applying the skills and knowledge I have learned." = "q2_4", 
         "Number of Responses" = "Number_of_Responses", 
         "Percent of Responses" = "percent_respondents") %>% 
  select(-n) %>% reactable(wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE)

# Question 2.4 in histogram
q2.4_hist <- survey_clean %>% select(starts_with("q2")) %>% count(q2_4, sort = TRUE) %>% mutate(percent_respondents = percent(n/sum(n), accuracy = .1),
q2_4 = factor(q2_4, levels = c("Disagree", "Somewhat agree", "Agree", "Strongly agree"))) %>% 
  ggplot(aes(q2_4, n, fill = q2_4)) +
  geom_histogram(stat = "identity", show.legend = FALSE)+
  scale_fill_viridis(discrete = TRUE, option = "magma", begin = .95, end = .5)+
  labs(x = "", y = "Number of responses", title = "The course stimulated new ways of applying the skills and knowledge I have learned.")+
  geom_text(aes(label = percent_respondents), color = "black", size = 6,
            vjust = -.1,
            family = "exo")+
  scale_y_continuous(breaks = c(10, 20, 30, 40, 50, 60), limits = c(0,60), expand = c(0, 0))+
  theme(text = element_text(family = "exo", size = 20))

q2.1_tab
q2.1_hist

q2.2_tab
q2.2_hist

q2.3_tab
q2.3_hist 

q2.4_tab
q2.4_hist


```

Students are generally favorable towards the program. For each of the questions at least 80% of the respondents either agree or strongly agree. From looking at the histograms one of the takeaways is that students feel less strongly about the fourth question "The course stimulated new ways of applying the skills and knowledge I have learned." This would be a good issue to explore further. An additional insight is that the highest percentage of responses for "somewhat agree" reside in the third question - "Course assignments allowed me to demonstrate my understanding of what I have learned in the course." 15% of respondents stated "Somewhat agree", a higher clip than for the other questions in this section. This may also need to be explored further.

Now moving on to the second set of questions which addresses effectiveness of different elements of the course. This set of questions is based on a 5 point Likert scale ranging from Not Effective at all to Extremely Effective.

As with the last set of questions, let's take a look at the responses to each question.

```{r Effectiveness of different elements of course, out.width="100%"}
# Making things a little easier, let's factor each variable and arrange it in order of the Likert scale

q3 <- survey_clean %>% select(starts_with("q3"))
colq3 <- q3 %>% colnames()
  
q3 %<>%
       mutate_each_(funs(factor(., levels = c("Not Effective at all", "Slightly Effective", "Somewhat Effective", "Effective", "Extremely Effective"))), colq3)



#We will create a function to make this go a little more smoothly
questions_3 <- c("How effectively do the following support your learning in this class? \n- Assigned readings",
                 "How effectively do the following support your learning in this class? \n- Pre-class work",
                 "How effectively do the following support your learning in this class? \n- Polls",
                 "How effectively do the following support your learning in this class? \n- Verbal discussions",
                 "How effectively do the following support your learning in this class? \n- Completing interactive activities in breakout sessions",
                 "How effectively do the following support your learning in this class? \n- Assignments",
                 "How effectively do the following support your learning in this class? \n- Face-to-face sessions")

q3names <- colnames(survey_clean %>% select(starts_with("q3")))

q3_tab <- function(col, question){
  return(q3 %>% count_(col) %>% mutate(Number_of_Responses = n,  percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
           rename_(.dots = setNames(col, question), 
         "Number of Responses" = "Number_of_Responses", 
         "Percent of Responses" = "percent_respondents") %>% 
  select(-n) %>% reactable(wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE))
}

q3_hist <- function(col, question, questiontext){
  qtable <- q3 %>% count_(col, sort = TRUE) %>% mutate(Number_of_Responses = n,  percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
           rename_(.dots = setNames(col, question)) %>%  
  select(-n)
  
  qtable <- as.data.frame(qtable)

 qtable %>% ggplot(aes_string(
    x = {{question}}, 
    y = "Number_of_Responses", 
    fill = {{question}}))+
  geom_histogram(stat = "identity", show.legend = FALSE)+
    scale_x_discrete(limits = c("Not Effective at all", "Slightly Effective", 
                                "Somewhat Effective", "Effective", "Extremely Effective"))+
    scale_fill_viridis(discrete = TRUE, option = "magma", begin = .95, end = .5)+
  labs(x = "", y = "Number of responses", title = questiontext)+
  geom_text(aes(label = percent_respondents), color = "black", size = 6,
            vjust = -.1,
            family = "exo")+
  scale_y_continuous(breaks = c(10, 20, 30, 40, 50, 60, 70), limits = c(0,75), expand = c(0, 0))+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 20))
}

q3tab_list <- map2(q3names, questions_3, q3_tab) # maps two arguments to the function that calls for two arguments. pmap maps more than two (look at Wickham R for Data Science pg.334)

q_s <- c("q3_1", "q3_2", "q3_3", "q3_4", "q3_5", "q3_6", "q3_7")

hist_3 <- list(q3names, q_s, questions_3)

q3hist_list <- hist_3 %>% pmap(q3_hist)


q3tab_list[[1]]
q3hist_list[[1]]

q3tab_list[[2]]
q3hist_list[[2]]

q3tab_list[[3]]
q3hist_list[[3]]

q3tab_list[[4]]
q3hist_list[[4]]

q3tab_list[[5]]
q3hist_list[[5]]

q3tab_list[[6]]
q3hist_list[[6]]

q3tab_list[[7]]
q3hist_list[[7]]
```

A look at the charts suggests that students believe verbal discussions are extremely effective. Verbal discussions have the most positive response rate. While most elements of the course rated favorably, the response with the most variability over the Likert scale was the effectiveness of face to face sessions. One would imagine face-to-face session would have facilitated discussions, but the two do not seem to be linked somehow. This is something to explore further.

Before moving to the free response questions we will take a look at the last set of questions that used the Likert scale. While on the surface it seems as if the same 5 point scale was used for the last set of questions, which deal with effectiveness of processes within the course, after looking at the responses, it is more likely that a 2 point scale was used: "Slightly Effective" and "Effective".

Completion rates were lower for this section: only 72% responded to each of these questions.

The same approach used in the previous sections will be employed here to get a snapshot of the responses for each question in this section. However, the results are limited with the smaller response rate and structure of the questions (the 2 point scale as opposed to the 5 point scale). Non-responses are removed, however the percentage in the histograms do reflect the percentage of all students.

```{r Effectiveness of Forum}
q5 <- survey_clean %>% select(starts_with("q5"))

colq5 <- q5 %>% colnames()
  
q5 %<>%
       mutate_each_(funs(factor(., levels = c("Slightly Effective", "Effective"))), colq5)

#Function to make this go a little more smoothly
questions_5 <- c("Based on your experience so far, how effective is Forum for: \n- Interacting with the instructor",
                 "Based on your experience so far, how effective is Forum for: \n- Interacting with your peers",
                 "Based on your experience so far, how effective is Forum for: \n- Keeping you engaged in learning",
                 "Based on your experience so far, how effective is Forum for: \n- Providing opportunities to practice what you are learning")

q5names <- colnames(survey_clean %>% select(starts_with("q5")))

q5_tab <- function(col, question){
  return(q5 %>% count_(col, sort = TRUE) %>% drop_na() %>%  mutate(Number_of_Responses = n,  percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
           rename_(.dots = setNames(col, question), 
         "Number of Responses" = "Number_of_Responses", 
         "Percent of Responses" = "percent_respondents") %>% 
  select(-n) %>% reactable(wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE))
}

q5_hist <- function(col, question, questiontext){
  qtable <- q5 %>% count_(col, sort = TRUE) %>% mutate(Number_of_Responses = n,  percent_respondents = percent(n/sum(n), accuracy = .1)) %>% 
           rename_(.dots = setNames(col, question)) %>%  
  select(-n)
  
  qtable <- as.data.frame(qtable)

 qtable %>% ggplot(aes_string(
    x = {{question}}, 
    y = "Number_of_Responses", 
    fill = {{question}}))+
  geom_histogram(stat = "identity", show.legend = FALSE)+
    scale_x_discrete(limits = c("Slightly Effective", 
                                 "Effective"))+
    scale_fill_viridis(discrete = TRUE, option = "magma", begin = .6, end = .9)+
  labs(x = "", y = "Number of responses", title = questiontext)+
  geom_text(aes(label = percent_respondents), color = "black", size = 6,
            vjust = -.1,
            family = "exo")+
  scale_y_continuous(breaks = c(10, 20, 30, 40, 50), limits = c(0,50), expand = c(0, 0))+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 20))
}

q5tab_list <- map2(q5names, questions_5, q5_tab) # maps two arguments to the function that calls for two arguments. pmap maps more than two (look at Wickham R for Data Science pg.334)

q_s <- c("q5_1", "q5_2", "q5_3", "q5_4")

hist_5 <- list(q5names, q_s, questions_5)

q5hist_list <- hist_5 %>% pmap(q5_hist)


q5tab_list[[1]]
q5hist_list[[1]]

q5tab_list[[2]]
q5hist_list[[2]]

q5tab_list[[3]]
q5hist_list[[3]]

q5tab_list[[4]]
q5hist_list[[4]]

```

There is little glean from these graphical representations. More data and more nuance would be needed.

Finally, there were two free response questions included in the survey. We will run a quick sentiment analysis on the comments to see if the comments were more positive or negative in tone.

```{r Senitment analysis of Question 4}
comments_q4 <- survey_clean %>% select(q4) %>% drop_na() %>% 
  filter(nchar(q4) > 2)

commentsq4 <- comments_q4$q4

q4sentiment <- sentiment_by(comments_q4$q4)

q4sentiment_comments <- cbind(q4sentiment, comments_q4)

q4sentiment_comments_tab <- q4sentiment_comments %>% rename("If any, what aspects of the course could be improved to better support your learning?" = "q4") %>%
  mutate(ave_sentiment = percent(ave_sentiment, accuracy = .1), 
         sd = percent(sd, accuracy = .1)) %>% 
  select(5, 4, 3, 2)

reactable(q4sentiment_comments_tab, wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE, resizable = TRUE)



q4sentiment_comments %>% ggplot(aes(ave_sentiment)) + geom_histogram()+
   labs(x = "Sentiment Score", 
       y = "Frequency of Score", 
       title  = "Overall Sentiment of Free Response Question 4", 
       subtitle = "If any, what aspects of the course could be improved to better support your learning?")+
  scale_y_continuous(expand = c(0, 0), limits = c(0, 10))
  
  


```

According to the sentiment analysis the responses to question 4, which addressed areas of improvement, were generally positive. In scrolling through the responses, some answers more directly offered suggestions for improvement and others were just general comments. There were a few comments noting the effectiveness of the professor. As was seen in the question about face-to-face sessions, some students commented on a need for restructuring these.

```{r Sentiment analysis for Question 6}
comments_q6 <- survey_clean %>% select(q6) %>% drop_na() %>% 
  filter(nchar(q6) > 2)

commentsq6 <- comments_q6$q6

q6sentiment <- sentiment_by(comments_q6$q6)

q6sentiment_comments <- cbind(q6sentiment, comments_q6)

q6sentiment_comments_tab <- q6sentiment_comments %>% rename("Please comment on your overall opinion of Forum's effectiveness in supporting your learning." = "q6") %>%
  mutate(ave_sentiment = percent(ave_sentiment, accuracy = .1), 
         sd = percent(sd, accuracy = .1)) %>% 
  select(5, 4, 3, 2)

reactable(q6sentiment_comments, wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE, resizable = TRUE)

q6sentiment_comments %>% ggplot(aes(ave_sentiment)) + geom_histogram()+
   labs(x = "Sentiment Score", 
       y = "Frequency of Score", 
       title  = "Overall Sentiment of Free Response Question 6", 
       subtitle = "Please comment on your overall opinion of Forum's effectiveness in supporting your learning.")+
  scale_y_continuous(expand = c(0, 0), limits = c(0, 12))
```

Question 6, which prompted the students to comment on the effectiveness of Forum, showed overall positive sentiment. According to this analysis, the students were favorable towards the Forum.

# Course Learning Outcomes

Now we move to data on student learning. We can get a good overview of the data in the tables below.

```{r Overview of Data}
#We clean the names of the variable first
outcomes <- outcomes %>% clean_names()

# Here is a look at the frequency of each learning outcome is measured
outcomes %>% count(learning_outcomes_name, sort = TRUE) %>% 
  reactable(theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE)

# Here is a look at the frequency of each assessment type is measured
outcomes %>% count(outcome_assessments_type, sort = TRUE) %>% 
  reactable(theme = fivethirtyeight(), striped = TRUE, fullWidth = TRUE)

#How many students and how many assessments they have taken
outcomes %>% count(target_users_id, sort = TRUE) %>% 
  reactable(theme = fivethirtyeight(), striped = TRUE, compact = TRUE)


# Assessments given for each class
outcomes %>% count(outcome_assessments_klass_id, sort = TRUE) %>% 
  reactable(theme = fivethirtyeight(), striped = TRUE, compact = TRUE)

# There is a lack of robust data for a couple of columns so we will bypass them in our analysis. Assessment ids have many have NAs. There is also some unclarity (even in the data dictionary) as to how the assignment weights work.
```

Logic and bias are learning outcomes that were addressed frequently in assessments (possibly disproportionately so). We can see from this also that there were 147 students in the data set but 12 have taken 3 or fewer assessments.

There is a lack of robust data for a couple of columns, so we will bypass them in our analysis. Assessment ids have many have NAs. There is also some unclarity (even in the data dictionary) as to how the assignment weights work.

## Scores Over Time

The first aspect we will look at is the relationship between scores over time by learning outcome. We will do this in two different charts: one chart will overlay all learning outcomes, while the other will facet them to make them easier to read.

```{r Scores over time by learning outcomes, out.width= "100%"}
# Line graph over time, avg. score on y-axis, line color by learning outcome type (for all students)
showtext.auto()
# All on one
outcomes %>% group_by(learning_outcomes_name, outcome_assessments_created_date) %>% 
  summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
  ggplot(aes(outcome_assessments_created_date, avg_score, color = learning_outcomes_name)) +
  geom_line(size = 1.5)+  
  scale_color_viridis(name = "Learning Outcomes", option = "magma", discrete = TRUE, begin = .9, end = .1)+
  labs(x = "", y = "Average Score", title = "Average score over time by learning outcomes")+
  scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 25)) 

# Faceted
outcomes %>% group_by(learning_outcomes_name, outcome_assessments_created_date) %>% 
  summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
  ggplot(aes(outcome_assessments_created_date, avg_score, color = learning_outcomes_name)) +
  geom_line(size = 1.5, show.legend = FALSE)+  
  scale_color_viridis(name = "Learning Outcomes", option = "magma", discrete = TRUE, begin = .9, end = .1)+
  labs(x = "", y = "Average Score", title = "Average score over time by learning outcomes")+
  theme_light()+
  scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
  facet_wrap(~ learning_outcomes_name)+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 20)) 

```

A look at these charts show a peculiar pattern: There seems to be an upward tick in scores for almost all learning outcomes (logic and science of learning excluded) in the month of November. This is a curious finding that would need further exploration to identify the cause. Many of the scores came down from their peak in November into December.

We can look at individual students' scores in the same manner. For the student with the ID 15375:

```{r Student score by learning outcome over time}
outcomes %>% filter(target_users_id == 15375) %>% 
  group_by(learning_outcomes_name, outcome_assessments_created_date) %>% 
  summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
  ggplot(aes(outcome_assessments_created_date, avg_score, color = learning_outcomes_name)) +
  geom_line(size = 1.5)+  
  scale_color_viridis(name = "Learning Outcomes", option = "magma", discrete = TRUE, begin = .9, end = .1)+
  labs(x = "", y = "Average Score", title = "Average score over time by learning outcomes")+
  scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 20))

outcomes %>% filter(target_users_id == 15375) %>% 
  group_by(learning_outcomes_name, outcome_assessments_created_date) %>% 
  summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
  ggplot(aes(outcome_assessments_created_date, avg_score, color = learning_outcomes_name)) +
  geom_line(size = 1.5, show.legend = FALSE)+  
  scale_color_viridis(name = "Learning Outcomes", option = "magma", discrete = TRUE, begin = .9, end = .1)+
  labs(x = "", y = "Average Score", title = "Average score over time by learning outcomes")+
  scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
  facet_wrap(~ learning_outcomes_name)+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 20))
```

Below is a function that can produce the same charts for the student ID that is entered. The example here is for student ID 15743.

(There is a way to make this interactive with Shiny apps, but unfortunately that is a little beyond my skill set right now. It is one of the next things to learn! For now, here is the function in the code chunk below.)

```{r Function for student scores by learning outcome}
student_outcome_scores <- function(x){
  outcomes %>% filter(target_users_id == x) %>% 
    group_by(learning_outcomes_name, outcome_assessments_created_date) %>% 
    summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
    ggplot(aes(outcome_assessments_created_date, avg_score, color = learning_outcomes_name)) +
    geom_line(size = 1.5)+  
    scale_color_viridis(name = "Learning Outcomes", option = "magma", discrete = TRUE, begin = .9, end = .1)+
    labs(x = "", y = "Average Score", title = "Average score over time by learning outcomes")+
    scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
    theme(text = element_text(family = "exo", size = 20),
          plot.title = element_text(size = 20))
}

#Function in action
student_outcome_scores(15743)


student_outcome_scores_facet <- function(x){
  outcomes %>% filter(target_users_id == x) %>% 
    group_by(learning_outcomes_name, outcome_assessments_created_date) %>% 
    summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
    ggplot(aes(outcome_assessments_created_date, avg_score, color = learning_outcomes_name)) +
    geom_line(size = 1.5, show.legend = FALSE)+  
    scale_color_viridis(name = "Learning Outcomes", option = "magma", discrete = TRUE, begin = .9, end = .1)+
    labs(x = "", y = "Average Score", title = "Average score over time by learning outcomes")+
    scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
    facet_wrap(~ learning_outcomes_name)+
    theme(text = element_text(family = "exo", size = 20),
          plot.title = element_text(size = 20))
}

#Function in action 
student_outcome_scores_facet(15743)
```

Next, we will take a look at scores over time by assessment type. It is similar to the concept above, but this time we will see the relationship between scores and assessment type. We can put this into one chart (no need to facet) because there are only five different assessment types.

```{r Scores over time by assessment type}

outcomes %>% group_by(outcome_assessments_type, outcome_assessments_created_date) %>% 
  summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
  ggplot(aes(outcome_assessments_created_date, avg_score, color = outcome_assessments_type)) +
  geom_line(size = 1.5)+  
  scale_color_viridis(name = "Assessment Type", option = "magma", discrete = TRUE, begin = .9, end = .1)+
  labs(x = "", y = "Average Score", title = "Average score over time by assessment type")+
  scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 20))
```

From the plot we can see that if the assessment was of a "general" type, it tended to score relatively low. However, as seen earlier, there were far fewer "general" assessment types overall. It would be interesting to have more information on what consitutes a "general" assessment. It would also be interesting to see if scores for each type were due to student's attitudes and efforts on the assessment type (e.g. student's not appreciating or putting as much effort into pre-class assignments), or if they were due to teacher/assessor attitudes and/or predilections.

As with the learning outcomes, we can zoom in and look at individual student scores by assessment type over time. Included in the chunk below is a function to search individual students. The first plot is for student ID 15375 and the second is for student ID 15743.

```{r Individual student scores over time by assessment type}

# Shows student scores over time by assessment type

outcomes %>% filter(target_users_id == 15375) %>%
  group_by(outcome_assessments_type, outcome_assessments_created_date) %>% 
  summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
  ggplot(aes(outcome_assessments_created_date, avg_score, color = outcome_assessments_type)) +
  geom_line(size = 1.5)+  
  scale_color_viridis(name = "Assessment Type", option = "magma", discrete = TRUE, begin = .9, end = .1)+
  labs(x = "", y = "Average Score", title = "Average score over time by assessment type")+
  scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
  theme(text = element_text(family = "exo", size = 20),
        plot.title = element_text(size = 20))

# Filter by student as function, so all you have to do is put in target_user_id
student_assessmenttype_scores <- function(x){
  outcomes %>% filter(target_users_id == x) %>%
    group_by(outcome_assessments_type, outcome_assessments_created_date) %>% 
    summarize(avg_score = mean(outcome_assessments_score, na.rm = TRUE)) %>% 
    ggplot(aes(outcome_assessments_created_date, avg_score, color = outcome_assessments_type)) +
    geom_line(size = 1.5)+  
    scale_color_viridis(name = "Assessment Type", option = "magma", discrete = TRUE, begin = .9, end = .1)+
    labs(x = "", y = "Average Score", title = "Average score over time by assessment type")+
    scale_y_continuous(breaks = c(1, 2, 3, 4), limits = c(0, 4.5))+
    theme(text = element_text(family = "exo", size = 20),
          plot.title = element_text(size = 20))
}

# Function in action
student_assessmenttype_scores(15743)
```

Combining both assessment type and learning outcome, we can take a look at the range, median, and quartiles of each assessment per learning outcome. First, we look at these in a traditional box plot. The learning outcomes have been grouped into eight categories. The top 7 - logic, bias, heuristics, science of learning, right problem, gap analysis, and break it down - all had close to at least 400 assessments to draw scores from (logic led the way with 1561). The rest had less than 300. Therefore, they were grouped into an "other" category.

```{r Box plot for assessment types by learning outcome}
# boxplots showing range, quartiles, and median of scores by assessment type for each outcome
outcomes %>% 
  mutate(learning_outcomes_name = fct_reorder(learning_outcomes_name, outcome_assessments_score, na.rm = TRUE),
         learning_outcomes_name = fct_lump_n(learning_outcomes_name, n = 7)) %>% 
  ggplot(aes(outcome_assessments_type, outcome_assessments_score, fill = outcome_assessments_type)) +
  geom_boxplot(show.legend = FALSE)+
  coord_flip() +
  labs(x = "", y = "Scores", title = "Scores by outcome and assessment type")+
  scale_fill_viridis(discrete = TRUE, option = "magma", begin = .9, end = .3)+
  facet_wrap(~ learning_outcomes_name)
```

For this purpose, it might be a little easier to draw conclusions from a ridgeline plot.

```{r Ridgeline plot for assessment types by learning outcome}
outcomes %>% 
  mutate(learning_outcomes_name = fct_reorder(learning_outcomes_name, outcome_assessments_score, na.rm = TRUE),
         learning_outcomes_name = fct_lump_n(learning_outcomes_name, n = 7)) %>% 
  ggplot(aes(outcome_assessments_score, outcome_assessments_type, fill = outcome_assessments_type)) +
  geom_density_ridges(show.legend = FALSE)+ 
  scale_fill_viridis(discrete = TRUE, option = "magma", begin = .9, end = .3)+
  facet_wrap(~ learning_outcomes_name)+
  labs(x = "Scores", y = "", title = "Scores by outcome and assessment type")+
  theme(
        axis.line=element_line(), 
        text = element_text(family = "exo", size = 20))
```

A few observations from the plots above. "Ridges" with high peaks suggest very low variability in score. Pre-class assignments in science of learning are notable: there is a large peak around 2. With large peaks, one wonders if students are aware of the expectations, if there is a default by the one assessing the work to gravitate towards a certain score, or if some other factor is at play. Other "ridges" are either bimodal (general assessments in break it down) or multimodal (much of the data presented here). It is interesting to see which assessments skew high or low. Videos skew high for each learning outcome, while pre-class assignments generally skew slightly lower.

The next plot helps us get a look at how all scores are distributed over time by both assessment type and learning outcome. There is a lot going on in this plot, and it looks a little wild, but the advantages of this plot include being able to identify trends (demonstrated by the regression lines) and being able to see if the learning outcomes are all being addressed equally. The underlying data and how assessments are recorded (on the first of each month) make the plots look a little goofy (in column format as opposed to spread out over time), but the general idea remains. The plot is displayed both statically and as an interactive. (Note, there were no assignments given in September.)

```{r Scores over time by learning outcomes and assessment type, out.width="100%"}
#Plotly graphs of each assessment by type and outcome over time
scores_by_assesstype <- outcomes %>% drop_na(outcome_assessments_score) %>% 
ggplot(aes(outcome_assessments_created_date, outcome_assessments_score, 
           label = target_users_id)) +
  geom_point() +
  geom_jitter(aes(color = learning_outcomes_name))+
  geom_smooth(method = "lm", color = "black") +
  labs(x = "", y = "Assessment Score", title = "Scores over time by type and outcome")+
  scale_color_viridis(name = "Learning Outcome", option = "magma", discrete = TRUE, begin = .95, end = .2)+
  facet_wrap(~ outcome_assessments_type, scales = "free")+
  theme(panel.spacing = unit(1.5, "lines"),
        axis.line=element_line(), 
        text = element_text(family = "exo", size = 15))

scores_by_assesstype

#For interactive plot 
ggplotly(scores_by_assesstype,)
```

From the plot we can see that all assessment types, except for general, had at least a slight upward trend. It is noticeable that logic seemed to be the theme during the month of October. More variation across time for each learning outcome might be a more desirable route.

Looking at the data in this manner can highlight trends across assessment type and learning outcomes.

## One Final Table

It might be helpful for teachers or administration to have a table which provides student score information and is easily searchable. Here is the beginning of such a table.

```{r}
student_avg_by_month <- outcomes %>% drop_na(outcome_assessments_score) %>% 
  group_by(target_users_id, outcome_assessments_created_date) %>% 
  summarize(avg_score = round(mean(outcome_assessments_score), digits = 2)) %>% 
  spread(outcome_assessments_created_date, avg_score) %>%
  rename("September 2021" = "2021-09-01", 
         "October 2021" = "2021-10-01", 
         "November 2021" = "2021-11-01", 
         "December 2021" = "2021-12-01") %>% 
  select(-"2022-01-01")

reactable(student_avg_by_month, wrap = TRUE, theme = fivethirtyeight(), striped = TRUE, 
          fullWidth = TRUE, searchable = TRUE, sortable = TRUE, filterable = TRUE, pageSizeOptions = 25, highlight = TRUE, showSortIcon = TRUE)
```

The table could be improved by parsing the scores even further by learning outcomes or types of assessment.

# Conclusions and Moving Forward

In reflecting on the analysis throughout, some general trends came to light:

-   The survey data suggests favorable attitudes by the students towards the course.

-   The course learning outcomes data suggests some learning outcomes are more of a focus than others (logic being predominant).

-   The course learning outcomes data suggests a slight upward trend in scores over time, although statistical tests would have to be performed to see if these are significant.

Areas of further analysis:

-   No exploration was done in regards to the Klass ID. Scores can be examined by the Klass ID to see if there are any trends on that level.

-   Clarity and more rigorous collection methods in the area of assessment weighting might provide clues about patterns of scores for each assessment type (e.g. why do preclass assignments tend to have lower scores?).

-   Statistical tests need to be run to compare the scores across each of these categories.

Suggestions in light of the findings:

-   As intimated earlier, some learning outcomes were addressed way more than others. Assessing each learning outcome an equal amount might be a better tactic. There were a couple of student comments that also suggested there could be more clarity about the learning outcomes. The learning outcomes are by nature abstract concepts/skills, and as such will invite at least slight variations in definition/understanding between individuals, but it might be desirable to be more clear in which tasks and content require which skill. Identifying which learning outcomes are working in concert on any given task, and being explicitly clear as to how, might help students start to identify the interconnectivity of these concepts for themselves.

-   The survey data suggested that face-to-face procedures may need to be revisited and revised. Not knowing the current format and practices, suggestions here are limited. However, from reading the comments it seems like these sessions could be used to practice the learning outcomes in more "real-world" situations.

-   More data regarding student progress is desired, though, the collection of this data should be as non-intrusive as possible. One does not want to create a culture of constant assessment. Novel ways to collect evidence, for instance through text mining/analytics, would allow the student to "act naturally" while evidence of their learning and understanding are being collected. In the survey data, verbal discussions rated very highly, however, these interactions are more difficult to assess. New technologies can help us gather, analyze, and evaluate understanding as demonstrated in verbal discussions, adding more data to provide a more comprehensive picture of student achievement.
